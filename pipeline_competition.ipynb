{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers import load_csv_data\n",
    "\n",
    "data_path = \"./data/train.csv\"\n",
    "test_path = \"./data/test.csv\"\n",
    "sample_path = \"./data/sample-submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30) (250000,) (250000,)\n",
      "[ 1.38470e+02  5.16550e+01  9.78270e+01  2.79800e+01  9.10000e-01\n",
      "  1.24711e+02  2.66600e+00  3.06400e+00  4.19280e+01  1.97760e+02\n",
      "  1.58200e+00  1.39600e+00  2.00000e-01  3.26380e+01  1.01700e+00\n",
      "  3.81000e-01  5.16260e+01  2.27300e+00 -2.41400e+00  1.68240e+01\n",
      " -2.77000e-01  2.58733e+02  2.00000e+00  6.74350e+01  2.15000e+00\n",
      "  4.44000e-01  4.60620e+01  1.24000e+00 -2.47500e+00  1.13497e+02] 1.0 100000\n"
     ]
    }
   ],
   "source": [
    "labels, features, ids = load_csv_data(data_path, sub_sample=False)\n",
    "\n",
    "print(features.shape, labels.shape, ids.shape)\n",
    "print(features[0], labels[0], ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import Preprocessor\n",
    "\n",
    "prep = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(features).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(200000, 96) (200000,)\n",
      "(50000, 96) (50000,)\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "from helpers import train_test_split\n",
    "\n",
    "features = prep.process_train(features, poly_degree=5)\n",
    "features_tr, features_te, labels_tr, labels_te = train_test_split(labels, features, 0.8, seed=432)\n",
    "\n",
    "print(np.isnan(features).sum())\n",
    "print(features_tr.shape, labels_tr.shape)\n",
    "print(features_te.shape, labels_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 MSE GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma:       0.01 \ttrain: [loss=0.38492, acc=0.7010]        \ttest: [loss=0.38482, accuracy=0.7010]\n",
      "gamma:  0.0158489 \ttrain: [loss=0.37617, acc=0.7051]        \ttest: [loss=0.37631, accuracy=0.7051]\n",
      "gamma:  0.0251189 \ttrain: [loss=0.36719, acc=0.7088]        \ttest: [loss=0.36756, accuracy=0.7088]\n",
      "gamma:  0.0398107 \ttrain: [loss=0.35920, acc=0.7136]        \ttest: [loss=0.35977, accuracy=0.7136]\n",
      "gamma:  0.0630957 \ttrain: [loss=0.35329, acc=0.7229]        \ttest: [loss=0.35398, accuracy=0.7229]\n",
      "gamma:        0.1 \ttrain: [loss=0.34939, acc=0.7288]        \ttest: [loss=0.35011, accuracy=0.7288]\n"
     ]
    }
   ],
   "source": [
    "from helpers import train_test_split, compute_loss, accuracy_score,make_prediction\n",
    "from implementations import mean_squared_error_gd\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(labels_tr, features_tr, ratio=0.8, seed=42)\n",
    "\n",
    "max_iter = 500\n",
    "# gammas = [1e-1, 3e-2, 1e-2, 3e-3, 1e-3]\n",
    "gammas = np.logspace(-2, -1, 6)\n",
    "mse = np.zeros((len(gammas), 2))\n",
    "\n",
    "initial_w = np.zeros((x_tr.shape[1]))\n",
    "\n",
    "\n",
    "for i, gamma in enumerate(gammas):\n",
    "\n",
    "    w, l_tr = mean_squared_error_gd(y_tr, x_tr, initial_w, max_iter, gamma)\n",
    "    l_te = compute_loss(y_te, x_te, w)\n",
    "\n",
    "    mse[i,:] = [l_tr, l_te]\n",
    "    acc_tr = accuracy_score(y_tr, make_prediction(x_tr @ w))\n",
    "    acc_te = accuracy_score(y_te, make_prediction(x_te @ w))\n",
    "\n",
    "    print(f\"gamma: {gamma:10g} \\ttrain: [loss={l_tr:.5f}, acc={acc_te:.4f}]\\\n",
    "        \\ttest: [loss={l_te:.5f}, accuracy={acc_te:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc=0.73564, test acc=0.73530\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on test set\n",
    "\n",
    "gamma = 0.1\n",
    "max_iter = 1000\n",
    "initial_w = np.zeros((features_tr.shape[1]))\n",
    "w, l_tr = mean_squared_error_gd(labels_tr, features_tr, initial_w, max_iter, gamma)\n",
    "\n",
    "acc_tr = accuracy_score(labels_tr, make_prediction(features_tr @ w))\n",
    "acc_te = accuracy_score(labels_te, make_prediction(features_te @ w))\n",
    "\n",
    "print(f\"train acc={acc_tr:.5f}, test acc={acc_te:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 MSE SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.0100 \ttrain: [loss=0.33259, acc=0.7587]        \ttest: [loss=0.33290, accuracy=0.7587]\n",
      "gamma: 0.0030 \ttrain: [loss=0.32993, acc=0.7599]        \ttest: [loss=0.33032, accuracy=0.7599]\n",
      "gamma: 0.0010 \ttrain: [loss=0.33164, acc=0.7538]        \ttest: [loss=0.33207, accuracy=0.7538]\n",
      "gamma: 0.0003 \ttrain: [loss=0.33935, acc=0.7427]        \ttest: [loss=0.33992, accuracy=0.7427]\n"
     ]
    }
   ],
   "source": [
    "from helpers import train_test_split, compute_loss, accuracy_score,make_prediction\n",
    "from implementations import mean_squared_error_sgd\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(labels_tr, features_tr, ratio=0.8, seed=42)\n",
    "\n",
    "max_iter = 5\n",
    "gammas = [1e-2, 3e-3, 1e-3, 3e-4]\n",
    "# gammas = np.logspace(-0.8,-2, 5)\n",
    "mse = np.zeros((len(gammas), 2))\n",
    "\n",
    "initial_w = np.zeros((x_tr.shape[1]))\n",
    "\n",
    "\n",
    "for i, gamma in enumerate(gammas):\n",
    "\n",
    "    w, l_tr = mean_squared_error_sgd(y_tr, x_tr, initial_w, max_iter, gamma)\n",
    "    l_te = compute_loss(y_te, x_te, w)\n",
    "\n",
    "    mse[i,:] = [l_tr, l_te]\n",
    "    acc_tr = accuracy_score(y_tr, make_prediction(x_tr @ w))\n",
    "    acc_te = accuracy_score(y_te, make_prediction(x_te @ w))\n",
    "\n",
    "    print(f\"gamma: {gamma:.4f} \\ttrain: [loss={mse[i,0]:.5f}, acc={acc_te:.4f}]\\\n",
    "        \\ttest: [loss={mse[i,1]:.5f}, accuracy={acc_te:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc=0.74936, test acc=0.75024\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on test set\n",
    "\n",
    "gamma = 3e-3\n",
    "max_iter = 10\n",
    "initial_w = np.zeros((features_tr.shape[1]))\n",
    "w, l_tr = mean_squared_error_sgd(labels_tr, features_tr, initial_w, max_iter, gamma)\n",
    "\n",
    "acc_tr = accuracy_score(labels_tr, make_prediction(features_tr @ w))\n",
    "acc_te = accuracy_score(labels_te, make_prediction(features_te @ w))\n",
    "\n",
    "print(f\"train acc={acc_tr:.5f}, test acc={acc_te:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Least Squares with normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss=0.31022, test loss=0.31490\n",
      "train acc=0.78219, test acc=0.78170\n"
     ]
    }
   ],
   "source": [
    "from implementations import least_squares\n",
    "\n",
    "# No hyperparameter to chosse\n",
    "\n",
    "w, l_tr = least_squares(labels_tr, features_tr)\n",
    "l_te = compute_loss(labels_te, features_te, w)\n",
    "acc_tr = accuracy_score(labels_tr, make_prediction(features_tr @ w))\n",
    "acc_te = accuracy_score(labels_te, make_prediction(features_te @ w))\n",
    "\n",
    "print(f\"train loss={l_tr:.5f}, test loss={l_te:.5f}\")\n",
    "print(f\"train acc={acc_tr:.5f}, test acc={acc_te:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Ridge Regression with normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_:           1e-10 \ttrain: [loss=0.30999, acc=0.77860]        \ttest: [loss=0.31168, accuracy=0.77860]\n",
      "lambda_:           1e-09 \ttrain: [loss=0.31038, acc=0.77797]        \ttest: [loss=0.31260, accuracy=0.77797]\n",
      "lambda_:           1e-08 \ttrain: [loss=0.31146, acc=0.77677]        \ttest: [loss=0.31383, accuracy=0.77677]\n",
      "lambda_:           1e-07 \ttrain: [loss=0.31431, acc=0.77297]        \ttest: [loss=0.31667, accuracy=0.77297]\n",
      "lambda_:           1e-06 \ttrain: [loss=0.31931, acc=0.76810]        \ttest: [loss=0.32114, accuracy=0.76810]\n",
      "lambda_:           1e-05 \ttrain: [loss=0.32231, acc=0.76487]        \ttest: [loss=0.32353, accuracy=0.76487]\n",
      "lambda_:          0.0001 \ttrain: [loss=0.32614, acc=0.76095]        \ttest: [loss=0.32676, accuracy=0.76095]\n",
      "lambda_:           0.001 \ttrain: [loss=0.33601, acc=0.74570]        \ttest: [loss=0.33652, accuracy=0.74570]\n",
      "lambda_:            0.01 \ttrain: [loss=0.35363, acc=0.72090]        \ttest: [loss=0.35416, accuracy=0.72090]\n",
      "lambda_:             0.1 \ttrain: [loss=0.38964, acc=0.69473]        \ttest: [loss=0.38952, accuracy=0.69473]\n"
     ]
    }
   ],
   "source": [
    "from helpers import train_test_split, compute_loss, accuracy_score,make_prediction\n",
    "from implementations import ridge_regression\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(labels_tr, features_tr, ratio=0.8, seed=42)\n",
    "\n",
    "max_iter = 3\n",
    "lambdas = np.logspace(-10, -1, 10)\n",
    "mse = np.zeros((len(lambdas), 2))\n",
    "\n",
    "\n",
    "for i, lambda_ in enumerate(lambdas):\n",
    "\n",
    "    w, l_tr = ridge_regression(y_tr, x_tr, lambda_)\n",
    "    l_te = compute_loss(y_te, x_te, w)\n",
    "\n",
    "    mse[i,:] = [l_tr, l_te]\n",
    "    acc_tr = accuracy_score(y_tr, make_prediction(x_tr @ w))\n",
    "    acc_te = accuracy_score(y_te, make_prediction(x_te @ w))\n",
    "\n",
    "    print(f\"lambda_: {lambda_:15g} \\ttrain: [loss={mse[i,0]:.5f}, acc={acc_te:.5f}]\\\n",
    "        \\ttest: [loss={mse[i,1]:.5f}, accuracy={acc_te:.5f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss=0.31025, test loss=0.31470\n",
      "train acc=0.78188, test acc=0.78130\n"
     ]
    }
   ],
   "source": [
    "from implementations import ridge_regression\n",
    "\n",
    "lambda_ = 1e-10\n",
    "\n",
    "w, l_tr = ridge_regression(labels_tr, features_tr, lambda_)\n",
    "l_te = compute_loss(labels_te, features_te, w)\n",
    "acc_tr = accuracy_score(labels_tr, make_prediction(features_tr @ w))\n",
    "acc_te = accuracy_score(labels_te, make_prediction(features_te @ w))\n",
    "\n",
    "print(f\"train loss={l_tr:.5f}, test loss={l_te:.5f}\")\n",
    "print(f\"train acc={acc_tr:.5f}, test acc={acc_te:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.1000 \ttrain: [loss=0.53501, acc=0.7150]        \ttest: [loss=0.53574, accuracy=0.7150]\n",
      "gamma: 0.0316 \ttrain: [loss=0.56142, acc=0.7044]        \ttest: [loss=0.56150, accuracy=0.7044]\n",
      "gamma: 0.0100 \ttrain: [loss=0.58508, acc=0.6860]        \ttest: [loss=0.58471, accuracy=0.6860]\n",
      "gamma: 0.0032 \ttrain: [loss=0.61188, acc=0.6572]        \ttest: [loss=0.61154, accuracy=0.6572]\n",
      "gamma: 0.0010 \ttrain: [loss=0.63848, acc=0.6572]        \ttest: [loss=0.63830, accuracy=0.6572]\n"
     ]
    }
   ],
   "source": [
    "from helpers import train_test_split, sigmoid, compute_loss_logistic, accuracy_score, make_prediction\n",
    "from implementations import logistic_regression\n",
    "\n",
    "# convert labels from {-1,1} to {0,1}\n",
    "labels_tr01 = 0.5 + labels_tr / 2.\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(labels_tr01, features_tr, ratio=0.8, seed=42)\n",
    "\n",
    "max_iter = 1000\n",
    "gammas = np.logspace(-1, -2, 5)\n",
    "# gammas = np.logspace(-0.8,-2, 5)\n",
    "mse = np.zeros((len(gammas), 2))\n",
    "\n",
    "initial_w = np.zeros((x_tr.shape[1]))\n",
    "\n",
    "\n",
    "for i, gamma in enumerate(gammas):\n",
    "\n",
    "    w, l_tr = logistic_regression(y_tr, x_tr, initial_w, max_iter, gamma)\n",
    "    l_te = compute_loss_logistic(y_te, x_te, w)\n",
    "\n",
    "    mse[i,:] = [l_tr, l_te]\n",
    "    acc_tr = accuracy_score(y_tr, make_prediction(sigmoid(x_tr @ w), logistic=True, zero_one=True))\n",
    "    acc_te = accuracy_score(y_te, make_prediction(sigmoid(x_te @ w), logistic=True, zero_one=True))\n",
    "\n",
    "    print(f\"gamma: {gamma:.4f} \\ttrain: [loss={l_tr:.5f}, acc={acc_te:.4f}]\\\n",
    "        \\ttest: [loss={l_te:.5f}, accuracy={acc_te:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc=0.65716, test acc=0.65802\n"
     ]
    }
   ],
   "source": [
    "from helpers import train_test_split, sigmoid, compute_loss_logistic, accuracy_score, make_prediction\n",
    "from implementations import logistic_regression\n",
    "\n",
    "# convert labels from {-1,1} to {0,1}\n",
    "labels_tr01 = 0.5 + labels_tr / 2.\n",
    "labels_te01 = 0.5 + labels_te / 2.\n",
    "\n",
    "max_iter = 2000\n",
    "gamma = 0.1\n",
    "\n",
    "initial_w = np.zeros((x_tr.shape[1]))\n",
    "\n",
    "w, l_tr = logistic_regression(labels_tr, features_tr, initial_w, max_iter, gamma)\n",
    "l_te = compute_loss_logistic(labels_te, features_te, w)\n",
    "\n",
    "acc_tr = accuracy_score(labels_tr01, make_prediction(sigmoid(features_tr @ w), logistic=True, zero_one=True))\n",
    "acc_te = accuracy_score(labels_te01, make_prediction(sigmoid(features_te @ w), logistic=True, zero_one=True))\n",
    "\n",
    "print(f\"train acc={acc_tr:.5f}, test acc={acc_te:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Regularized Logisic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 1.0000, lambda_: 0.1000            \ttrain: [loss=0.62910, acc=0.6590]            \ttest: [loss=0.60728, accuracy=0.6590]\n",
      "gamma: 1.0000, lambda_: 0.0100            \ttrain: [loss=0.57896, acc=0.7040]            \ttest: [loss=0.55728, accuracy=0.7040]\n",
      "gamma: 1.0000, lambda_: 0.0010            \ttrain: [loss=0.53422, acc=0.7298]            \ttest: [loss=0.52029, accuracy=0.7298]\n",
      "gamma: 1.0000, lambda_: 0.0001            \ttrain: [loss=0.51244, acc=0.7405]            \ttest: [loss=0.50991, accuracy=0.7405]\n",
      "gamma: 0.4642, lambda_: 0.1000            \ttrain: [loss=0.62910, acc=0.6590]            \ttest: [loss=0.60728, accuracy=0.6590]\n",
      "gamma: 0.4642, lambda_: 0.0100            \ttrain: [loss=0.57896, acc=0.7040]            \ttest: [loss=0.55728, accuracy=0.7040]\n",
      "gamma: 0.4642, lambda_: 0.0010            \ttrain: [loss=0.53474, acc=0.7277]            \ttest: [loss=0.52283, accuracy=0.7277]\n",
      "gamma: 0.4642, lambda_: 0.0001            \ttrain: [loss=0.51829, acc=0.7339]            \ttest: [loss=0.51713, accuracy=0.7339]\n",
      "gamma: 0.2154, lambda_: 0.1000            \ttrain: [loss=0.62910, acc=0.6590]            \ttest: [loss=0.60728, accuracy=0.6590]\n",
      "gamma: 0.2154, lambda_: 0.0100            \ttrain: [loss=0.57896, acc=0.7040]            \ttest: [loss=0.55734, accuracy=0.7040]\n",
      "gamma: 0.2154, lambda_: 0.0010            \ttrain: [loss=0.53680, acc=0.7226]            \ttest: [loss=0.52815, accuracy=0.7226]\n",
      "gamma: 0.2154, lambda_: 0.0001            \ttrain: [loss=0.52484, acc=0.7267]            \ttest: [loss=0.52452, accuracy=0.7267]\n",
      "gamma: 0.1000, lambda_: 0.1000            \ttrain: [loss=0.62910, acc=0.6590]            \ttest: [loss=0.60728, accuracy=0.6590]\n",
      "gamma: 0.1000, lambda_: 0.0100            \ttrain: [loss=0.57901, acc=0.7035]            \ttest: [loss=0.55873, accuracy=0.7035]\n",
      "gamma: 0.1000, lambda_: 0.0010            \ttrain: [loss=0.54326, acc=0.7123]            \ttest: [loss=0.53839, accuracy=0.7123]\n",
      "gamma: 0.1000, lambda_: 0.0001            \ttrain: [loss=0.53591, acc=0.7147]            \ttest: [loss=0.53601, accuracy=0.7147]\n"
     ]
    }
   ],
   "source": [
    "from helpers import train_test_split, sigmoid, compute_loss_logistic, accuracy_score, make_prediction\n",
    "from implementations import reg_logistic_regression\n",
    "\n",
    "# convert labels from {-1,1} to {0,1}\n",
    "labels_tr01 = 0.5 + labels_tr / 2.\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(labels_tr01, features_tr, ratio=0.8, seed=42)\n",
    "\n",
    "max_iter = 1000\n",
    "lambda_ = 0.001\n",
    "lambdas = np.logspace(-1,-4, 4)\n",
    "gamma = 0.08\n",
    "gammas = np.logspace(0, -1, 4)\n",
    "# gammas = np.logspace(-0.8,-2, 5)\n",
    "\n",
    "initial_w = np.zeros((x_tr.shape[1]))\n",
    "\n",
    "\n",
    "for i, gamma in enumerate(gammas):\n",
    "    for j, lambda_ in enumerate(lambdas):\n",
    "\n",
    "        w, l_tr = reg_logistic_regression(y_tr, x_tr, lambda_, initial_w, max_iter, gamma)\n",
    "        l_te = compute_loss_logistic(y_te, x_te, w)\n",
    "\n",
    "        acc_tr = accuracy_score(y_tr, make_prediction(sigmoid(x_tr @ w), logistic=True, zero_one=True))\n",
    "        acc_te = accuracy_score(y_te, make_prediction(sigmoid(x_te @ w), logistic=True, zero_one=True))\n",
    "\n",
    "        print(f\"gamma: {gamma:.4f}, lambda_: {lambda_:.4f}\\\n",
    "            \\ttrain: [loss={l_tr:.5f}, acc={acc_te:.4f}]\\\n",
    "            \\ttest: [loss={l_te:.5f}, accuracy={acc_te:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc=0.65716, test acc=0.65802\n"
     ]
    }
   ],
   "source": [
    "from helpers import train_test_split, sigmoid, compute_loss_logistic, accuracy_score, make_prediction\n",
    "from implementations import reg_logistic_regression\n",
    "\n",
    "# convert labels from {-1,1} to {0,1}\n",
    "labels_tr01 = 0.5 + labels_tr / 2.\n",
    "labels_te01 = 0.5 + labels_te / 2.\n",
    "\n",
    "max_iter = 1000\n",
    "gamma = 0.5\n",
    "lambda_ = 1e-4\n",
    "\n",
    "initial_w = np.zeros((x_tr.shape[1]))\n",
    "\n",
    "w, l_tr = reg_logistic_regression(labels_tr, features_tr, lambda_, initial_w, max_iter, gamma)\n",
    "l_te = compute_loss_logistic(labels_te, features_te, w)\n",
    "\n",
    "acc_tr = accuracy_score(labels_tr01, make_prediction(sigmoid(features_tr @ w), logistic=True, zero_one=True))\n",
    "acc_te = accuracy_score(labels_te01, make_prediction(sigmoid(features_te @ w), logistic=True, zero_one=True))\n",
    "\n",
    "print(f\"train acc={acc_tr:.5f}, test acc={acc_te:.5f}\")\n",
    "# The results are not as good as in training, possibly caused by outliers in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "_ , features_submit, ids_submit = load_csv_data(test_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a model and train it on the whole dataset\n",
    "# TODO\n",
    "\n",
    "# Make prediction\n",
    "pred = None # TODO\n",
    "\n",
    "\n",
    "# EXample with MSE GD\n",
    "from implementations import mean_squared_error_gd\n",
    "gamma = 3e-2\n",
    "max_iter = 2000\n",
    "initial_w = np.zeros((features.shape[1]))\n",
    "w, l_tr = mean_squared_error_gd(labels, features, initial_w, max_iter, gamma)\n",
    "\n",
    "from helpers import make_prediction\n",
    "pred = make_prediction(features_submit @ w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file \n",
    "\n",
    "from helpers import create_csv_submission\n",
    "\n",
    "create_csv_submission(ids_submit, pred, sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml-cs433')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c300989436866e0f2bdaf2ad700bc3bcca33acbeb9f30e204547f5a0aa3fb11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
